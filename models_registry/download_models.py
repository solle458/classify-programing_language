"""
ãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å†æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Streamlit Cloud ãƒ‡ãƒ—ãƒ­ã‚¤ç”¨
"""
import os
import pickle
import json
from pathlib import Path
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib

def rebuild_model():
    """
    è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰
    GitHub 100MBåˆ¶é™å¯¾å¿œ
    """
    try:
        print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰ä¸­...")
        
        # å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        import sys
        sys.path.append('.')
        from src.data.loader import DataLoaderFactory
        from src.models.classifier import LogisticRegressionModel
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print("ğŸ“¥ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        data_loader = DataLoaderFactory.create_loader(
            "programming_language", 
            min_samples_per_class=200
        )
        y_train, X_train, _, _ = data_loader.load()
        
        # è»½é‡è¨­å®šã§TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
        print("ğŸ”§ TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’æ§‹ç¯‰ä¸­...")
        vectorizer = TfidfVectorizer(
            max_features=5000,  # ç‰¹å¾´é‡ã‚’5000ã«åˆ¶é™
            ngram_range=(1, 2),
            max_df=0.95,
            min_df=2,
            stop_words='english'
        )
        
        # å‰å‡¦ç†
        X_train_tfidf = vectorizer.fit_transform(X_train)
        
        # è»½é‡ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        print("ğŸ¤– è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        model = LogisticRegression(
            max_iter=500,  # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã‚’å‰Šæ¸›
            solver='saga',
            n_jobs=1,  # Cloudç’°å¢ƒç”¨
            random_state=42
        )
        model.fit(X_train_tfidf, y_train)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡
        print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚’è©•ä¾¡ä¸­...")
        y_train, X_train, y_test, X_test = data_loader.load()
        X_test_tfidf = vectorizer.transform(X_test)
        
        # äºˆæ¸¬ã¨è©•ä¾¡
        y_pred = model.predict(X_test_tfidf)
        from sklearn.metrics import accuracy_score, f1_score
        
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        print(f"ğŸ¯ ç²¾åº¦: {accuracy:.4f}")
        print(f"ğŸ¯ F1ã‚¹ã‚³ã‚¢: {f1:.4f}")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_path = "models_registry/lr_baseline_001.joblib"
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ä¸­: {model_path}")
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä¸€ç·’ã«ä¿å­˜
        model_data = {
            'model': model,
            'vectorizer': vectorizer,
            'classes': model.classes_,
            'performance': {
                'accuracy': float(accuracy),
                'f1_score': float(f1),
                'n_features': 5000,
                'n_classes': len(model.classes_)
            }
        }
        
        joblib.dump(model_data, model_path)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        file_size = os.path.getsize(model_path) / (1024 * 1024)
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«å†æ§‹ç¯‰å®Œäº†! ã‚µã‚¤ã‚º: {file_size:.1f}MB")
        
        # model_info.jsonã‚’æ›´æ–°
        update_model_info(accuracy, f1, file_size)
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«å†æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def update_model_info(accuracy: float, f1_score: float, file_size_mb: float):
    """model_info.jsonã‚’å®Ÿéš›ã®æ€§èƒ½ã§æ›´æ–°"""
    try:
        import json
        import time
        
        model_info = {
            "models": [
                {
                    "id": "lr_baseline_001",
                    "name": "LR Cloud Optimized (Auto-generated)",
                    "type": "logistic_regression",
                    "file_path": "models_registry/lr_baseline_001.joblib",
                    "accuracy": round(accuracy, 4),
                    "f1_score": round(f1_score, 4),
                    "file_size_mb": round(file_size_mb, 1),
                    "created_at": time.strftime("%Y-%m-%dT%H:%M:%S"),
                    "is_active": True,
                    "description": f"Auto-generated lightweight model (max_features=5000). Accuracy: {accuracy:.2%}"
                }
            ],
            "default_model_id": "lr_baseline_001"
        }
        
        with open("models_registry/model_info.json", "w") as f:
            json.dump(model_info, f, indent=2)
        
        print(f"ğŸ“ model_info.jsonæ›´æ–°å®Œäº† (ç²¾åº¦: {accuracy:.2%})")
        
    except Exception as e:
        print(f"âš ï¸ model_info.jsonæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

def ensure_model_exists():
    """ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å†æ§‹ç¯‰"""
    model_path = "models_registry/lr_baseline_001.joblib"
    
    if not os.path.exists(model_path):
        print("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†æ§‹ç¯‰ã—ã¾ã™...")
        return rebuild_model()
    else:
        print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã™")
        return True

if __name__ == "__main__":
    ensure_model_exists()
